{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOqbW0NtE1ljRXAFAF5zETH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "65d5a8ba475940acb19f83bcc8cd5539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_004aa00e57dd46bc950e7cb998d6f08a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_39482056bcc3419398fc17cd0bc4c1f4",
              "IPY_MODEL_b021d5f330f6406b8036072eeb21232e"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "004aa00e57dd46bc950e7cb998d6f08a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "39482056bcc3419398fc17cd0bc4c1f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b52114c8387146878a9e4038ad7e1a63",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d880f4ff7a4c446ca883b6c803652c11"
          },
          "model_module_version": "1.5.0"
        },
        "b021d5f330f6406b8036072eeb21232e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e4b7e886618f4c5287bf276085fc04de",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 82/? [00:31&lt;00:00,  2.64it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_76012fedd5ca49558311460acf1399ac"
          },
          "model_module_version": "1.5.0"
        },
        "b52114c8387146878a9e4038ad7e1a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "d880f4ff7a4c446ca883b6c803652c11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "e4b7e886618f4c5287bf276085fc04de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "76012fedd5ca49558311460acf1399ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bkricardo/attention_base_speech_to_text/blob/main/final_model_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbX92S2RlYz5",
        "outputId": "628e618a-56bd-41d7-947a-2bd06b6e5c6f"
      },
      "source": [
        "from google.colab import drive\n",
        "import json\n",
        "drive.mount(\"/content/gdrive\",force_remount=True)\n",
        "%cd ./gdrive/My Drive/11785-hw/hw4/data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/11785-hw/hw4/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esX9ukCLl1BE",
        "outputId": "66136a8e-3300-4933-c124-717cb235349c"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiStse93l1ZD",
        "outputId": "69a48e9f-5189-48c3-ace6-9c1d74b61730"
      },
      "source": [
        "!pip install kaggle\n",
        "!mkdir .kaggle\n",
        "\n",
        "token = {\"username\":\"bkyuanpeiw\",\"key\":\"da89ec8ea1e4ac3d0df30a0597685d40\"}\n",
        "with open('/content/.kaggle/kaggle.json','w') as file:\n",
        "    json.dump(token,file)\n",
        "\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "mkdir: cannot create directory â€˜.kaggleâ€™: File exists\n",
            "- path is now set to: {/content}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts5FhEkFoKve",
        "outputId": "ddd1eb66-865e-4142-fda2-c2ea965b0657"
      },
      "source": [
        "'''\n",
        "@Author: yuanpei-wang\n",
        "@Last Edit: 2021/03/28\n",
        "'''\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.utils.rnn as rnn_utils\n",
        "import torch.optim as optim\n",
        "import torch.nn.utils as utils\n",
        "from torch.autograd import Variable\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import random\n",
        "from torch.utils import data\n",
        "\n",
        "from tqdm.notebook import tqdm as tq\n",
        "from torch.nn.utils.rnn import *\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "print(cuda, sys.version)\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "np.random.seed(11785)\n",
        "torch.manual_seed(11785)\n",
        "\n",
        "LETTER_LIST = ['<sos>', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', \\\n",
        "         'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '-', \"'\", '.', '_', '+', ' ', '<eos>']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True 3.7.10 (default, Feb 20 2021, 21:17:23) \n",
            "[GCC 7.5.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IguUJTRZogx1"
      },
      "source": [
        "def create_dictionaries(letter_list):\n",
        "    '''\n",
        "    Create dictionaries for letter2index and index2letter transformations\n",
        "    '''\n",
        "    letter2index = dict()\n",
        "    index2letter = dict()\n",
        "    for index, letter in enumerate(LETTER_LIST):\n",
        "        letter2index[letter] = index\n",
        "        index2letter[index] = letter\n",
        "\n",
        "    return letter2index, index2letter\n",
        "\n",
        "\n",
        "def transform_letter_to_index(raw_transcripts):\n",
        "    '''\n",
        "    Transforms text input to numerical input by converting each letter\n",
        "    to its corresponding index from letter_list\n",
        "\n",
        "    Args:\n",
        "        raw_transcripts: Raw text transcripts with the shape of (N, )\n",
        "\n",
        "    Return:\n",
        "        transcripts: Converted index-format transcripts. This would be a list with a length of N\n",
        "    '''\n",
        "    index_list = []\n",
        "    for sentence in raw_transcripts:\n",
        "        letters = [letter2index['<sos>']]\n",
        "        # print(sentence)\n",
        "        for word in sentence:\n",
        "            # print(word)\n",
        "            new_word = word.decode('utf-8')\n",
        "\n",
        "            for char in new_word:\n",
        "                letters.append(letter2index[char])\n",
        "\n",
        "            letters.append(letter2index[' '])\n",
        "        letters.pop()\n",
        "        letters.append(letter2index['<eos>'])\n",
        "        index_list.append(letters)\n",
        "\n",
        "    return index_list\n",
        "\n",
        "# Create the letter2index and index2letter dictionary\n",
        "letter2index, index2letter = create_dictionaries(LETTER_LIST)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZ1lQgrso7dM",
        "outputId": "fc2294bf-ed6d-41dd-957f-6b0c8de5fec6"
      },
      "source": [
        "%cd ./gdrive/My Drive/11785-hw/hw4/data\n",
        "test_data = np.load('test.npy', allow_pickle=True, encoding='bytes')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/11785-hw/hw4/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LChzJ78wpAic"
      },
      "source": [
        "class MyDataset(data.Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # For testing set, return only x\n",
        "        if self.Y == None:\n",
        "            return torch.tensor(self.X[index].astype(np.float32))\n",
        "        # For training and validation set, return x and y\n",
        "        else:\n",
        "            return torch.tensor(self.X[index].astype(np.float32)), torch.tensor(self.Y[index])\n",
        "\n",
        "def collate_test(data):\n",
        "    \"\"\"\n",
        "    Return:\n",
        "        pad_x: the padded x (testing speech data)\n",
        "        x_len: the length of x\n",
        "    \"\"\"\n",
        "    inputs = [x for x in data]\n",
        "    inputs_pad = pad_sequence(inputs, batch_first=True) # dim (B, T, C) since batch_first is true, (T, B, C) if false\n",
        "    inputs_lens = torch.LongTensor([len(x) for x in data])\n",
        "\n",
        "    return inputs_pad,inputs_lens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_I3iIVRpKyW"
      },
      "source": [
        "test_dataset = MyDataset(test_data,Y= None)\n",
        "test_loader = data.DataLoader(\n",
        "            dataset = test_dataset,\n",
        "            batch_size = 32,\n",
        "            num_workers = 4,\n",
        "            shuffle = False,\n",
        "            collate_fn = collate_test,\n",
        "            pin_memory = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lM6XL9GLpeFM"
      },
      "source": [
        "class pBLSTM(nn.Module):\n",
        "    '''\n",
        "    Pyramidal BiLSTM\n",
        "    Read paper and understand the concepts and then write your implementation here.\n",
        "    '''\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super(pBLSTM, self).__init__()\n",
        "        self.blstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim, num_layers=1, bidirectional=True, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x_padded, x_len = pad_packed_sequence(x, batch_first=True)  #(B,T ,hidden), unpack x\n",
        "\n",
        "        x_len.to(device)\n",
        "\n",
        "        # cut the x_padded if time length is odd\n",
        "        x_padded = x_padded[:,:(x_padded.size(1) // 2) * 2, :]\n",
        "\n",
        "        #concat 2 time step to 1 time step with 2 dimension concated, (B, T/2, hidden * 2)\n",
        "        x_concat = x_padded.reshape(x_padded.size(0), x_padded.size(1) // 2, x_padded.size(2) * 2)\n",
        "        x_len = x_len // 2\n",
        "\n",
        "        x_packed = pack_padded_sequence(x_concat,lengths = x_len, enforce_sorted=False, batch_first=True)\n",
        "\n",
        "        out = self.blstm(x_packed)[0]\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DY-z615opjZF"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    '''\n",
        "    Encoder takes the utterances as inputs and returns the key, value and unpacked_x_len.\n",
        "    Key and value are linear projections of the output from pBLSTM network for the laster.\n",
        "    '''\n",
        "    def __init__(self, input_dim, encoder_hidden_dim, key_value_size=128):\n",
        "        super(Encoder, self).__init__()\n",
        "        # The first LSTM at the very bottom\n",
        "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=encoder_hidden_dim, bidirectional=True, batch_first=True)\n",
        "\n",
        "\n",
        "        # TODO: Define the blocks of pBLSTMs\n",
        "        # ...\n",
        "        self.plstm = nn.Sequential(\n",
        "            pBLSTM(encoder_hidden_dim*4, encoder_hidden_dim),\n",
        "            pBLSTM(encoder_hidden_dim*4, encoder_hidden_dim),\n",
        "            pBLSTM(encoder_hidden_dim*4, encoder_hidden_dim)\n",
        "        )\n",
        "\n",
        "        # The linear transformation for producing Key and Value for attention\n",
        "        # Since you are using bidirectional LSTM, be careful about the size of hidden dimension\n",
        "        self.key_network = nn.Linear(encoder_hidden_dim*2, key_value_size)\n",
        "        self.value_network = nn.Linear(encoder_hidden_dim*2, key_value_size)\n",
        "\n",
        "    def forward(self, x, x_len):\n",
        "        # Pass through the first LSTM at the very bottom\n",
        "        packed_sequence = rnn_utils.pack_padded_sequence(x, x_len, enforce_sorted=False, batch_first=True)\n",
        "        out, _ = self.lstm(packed_sequence)\n",
        "\n",
        "\n",
        "        # TODO: Pass through the pBLSTM blocks\n",
        "        out = self.plstm(out)\n",
        "\n",
        "        # Unpack the sequence and get the Key and Value for attention\n",
        "        unpacked_out, unpacked_len = pad_packed_sequence(out,batch_first=True)\n",
        "\n",
        "        key = self.key_network(unpacked_out)\n",
        "        value = self.value_network(unpacked_out)\n",
        "\n",
        "        # return key, value, unpacked_x_len\n",
        "        return key, value, unpacked_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4HaKTebpl41"
      },
      "source": [
        "def plot_attention(attention):\n",
        "    plt.clf()\n",
        "    sns.heatmap(attention, cmap='GnBu')\n",
        "    plt.show()\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    '''\n",
        "    Attention is calculated using key, value and query from Encoder and decoder.\n",
        "    Below are the set of operations you need to perform for computing attention:\n",
        "        energy = bmm(key, query)\n",
        "        attention = softmax(energy)\n",
        "        context = bmm(attention, value)\n",
        "    '''\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Attention, self).__init__()\n",
        "\n",
        "    def forward(self, query, key, value, lengths):\n",
        "        \"\"\"\n",
        "            :param query: (batch_size, hidden_size), decoder state of a single timestep\n",
        "            :param key: (batch_size, max_len, key_value_size), encoded input sequences for key projection\n",
        "            :param value: (batch_size, max_len, key_value_size), encoded input sequences for value projection\n",
        "            :param lengths: (batch_size,), lengths of source sequences\n",
        "            :returns: (batch_size, hidden_size) attended source context, and (batch_size, max_len) attention vectors\n",
        "        \"\"\"\n",
        "        # Compute (batch_size, max_len) attention logits. \"bmm\" stands for \"batch matrix multiplication\".\n",
        "        # Input shape of bmm:  (batch_szie, max_len, hidden_size), (batch_size, hidden_size, 1)\n",
        "        # Output shape of bmm: (batch_size, max_len, 1)\n",
        "        #hidden should = key_value_size\n",
        "        energy = torch.bmm(key, query.unsqueeze(2)).squeeze(2) #(B,max_len, key_value_size) * (B, hidden_size,1) = (B, max_len,1) -> (B, max_len)\n",
        "\n",
        "        # Create an (batch_size, max_len) boolean mask for all padding positions\n",
        "        # Make use of broadcasting: (1, max_len), (batch_size, 1) -> (batch_size, max_len)\n",
        "        mask = torch.arange(key.size(1)).unsqueeze(0) >= lengths.unsqueeze(1)\n",
        "        mask = mask.to(device)\n",
        "\n",
        "        # Set attention logits at padding positions to negative infinity.\n",
        "        energy.masked_fill_(mask, -1e9) # (B, max_len)\n",
        "\n",
        "        # Take softmax over the \"source length\" dimension.\n",
        "        attention = nn.functional.softmax(energy, dim = 1)\n",
        "\n",
        "        # Compute attention-weighted sum of context vectors\n",
        "        # Input shape of bmm: (batch_size, 1, max_len), (batch_size, max_len, hidden_size)\n",
        "        # Output shape of bmm: (batch_size, 1, hidden_size)\n",
        "        context = torch.bmm(attention.unsqueeze(1), value).squeeze(1)   #(B,1, max_len) * (B,max_len,hiddn) = (B,1,hidden) -> (B,hidden)\n",
        "\n",
        "\n",
        "        return context, attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_QtCJZTpq-w"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    '''\n",
        "    As mentioned in a previous recitation, each forward call of decoder deals with just one time step.\n",
        "    Thus we use LSTMCell instead of LSTM here.\n",
        "    The output from the seond LSTMCell can be used as query for calculating attention.\n",
        "    In place of value that we get from the attention, this can be replace by context we get from the attention.\n",
        "    Methods like Gumble noise and teacher forcing can also be incorporated for improving the performance.\n",
        "    '''\n",
        "    def __init__(self, vocab_size, decoder_hidden_dim, embed_dim, key_value_size=128):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=letter2index['<eos>'])\n",
        "        self.lstm1 = nn.LSTMCell(input_size=embed_dim + key_value_size, hidden_size=decoder_hidden_dim)\n",
        "        self.lstm2 = nn.LSTMCell(input_size=decoder_hidden_dim, hidden_size=key_value_size)\n",
        "        self.drop1 = LockedDropout(dropout = 0.2)\n",
        "        self.drop2 = LockedDropout(dropout = 0.2)\n",
        "\n",
        "        self.attention = Attention()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.character_prob = nn.Linear(2 * key_value_size, vocab_size)\n",
        "        self.key_value_size = key_value_size\n",
        "\n",
        "        self.character_prob.weight=self.embedding.weight\n",
        "\n",
        "    def forward(self, key, value, encoder_len, y=None, mode='train',teacher_f = 0.1):\n",
        "        '''\n",
        "        Args:\n",
        "            key :(B, T, key_value_size) - Output of the Encoder Key projection layer\n",
        "            value: (B, T, key_value_size) - Output of the Encoder Value projection layer\n",
        "            y: (T, text_len) - Batch input of text with text_length\n",
        "            mode: Train or eval mode\n",
        "        Return:\n",
        "            predictions: the character perdiction probability\n",
        "        '''\n",
        "\n",
        "        B, key_seq_max_len, key_value_size = key.shape\n",
        "\n",
        "\n",
        "        if mode == 'train':\n",
        "            max_len =  y.shape[1]\n",
        "            char_embeddings = self.embedding(y)   # (B,T, hidden_size)\n",
        "        else:\n",
        "            max_len = 600\n",
        "\n",
        "        # TODO: Create the attention mask here (outside the for loop rather than inside) to aviod repetition\n",
        "        # Had already done in Attention()\n",
        "\n",
        "        predictions = []\n",
        "        prediction = torch.zeros(B, 1).to(device)\n",
        "        hidden_states = [None, None]\n",
        "\n",
        "        # TODO: Initialize the context. Be careful here\n",
        "        context = torch.zeros(B,key_value_size).to(device)\n",
        "        attentionPlot = []\n",
        "        for i in range(max_len):\n",
        "            if mode == 'train':\n",
        "                # TODO: Implement (1) Teacher Forcing and (2) Gumble Noise techniques here\n",
        "                teacher_force = True if np.random.random_sample() > teacher_f else False #set teacher forceing with 0.9\n",
        "\n",
        "                if i == 0: #start character always <sos>\n",
        "                        start_char = torch.zeros(B, dtype=torch.long).fill_(letter2index['<sos>']).to(device) #\n",
        "                        char_embed = self.embedding(start_char)\n",
        "                else:\n",
        "                    if teacher_force:\n",
        "                        char_embed = char_embeddings[:, i - 1, :]\n",
        "                    else:\n",
        "                        char_embed = self.embedding(prediction.argmax(dim=-1))\n",
        "            else:\n",
        "                if i ==0:\n",
        "                    start_char = torch.zeros(B, dtype=torch.long).fill_(letter2index['<sos>']).to(device) #\n",
        "                    char_embed = self.embedding(start_char)\n",
        "                else:\n",
        "                    char_embed = self.embedding(prediction.argmax(dim=-1))\n",
        "\n",
        "            y_context = torch.cat([char_embed, context], dim=1)\n",
        "            y_context = self.drop1(y_context.unsqueeze(1)).squeeze(1)\n",
        "            hidden_states[0] = self.lstm1(y_context, hidden_states[0])\n",
        "\n",
        "            lstm1_hidden = hidden_states[0][0]\n",
        "            lstm1_hidden = self.drop1(lstm1_hidden.unsqueeze(1)).squeeze(1)\n",
        "            hidden_states[1] = self.lstm2(lstm1_hidden, hidden_states[1])\n",
        "            output = hidden_states[1][0]\n",
        "\n",
        "            # TODO: Compute attention from the output of the second LSTM Cell\n",
        "\n",
        "            context, attention = self.attention(output, key, value, encoder_len)\n",
        "\n",
        "\n",
        "            # plot_attention(attention=attention)\n",
        "            if mode == 'train':\n",
        "                curr_attention = attention[0].detach().cpu()\n",
        "                # print(curr_attention.shape)\n",
        "                attentionPlot.append(curr_attention)\n",
        "\n",
        "            output_context = torch.cat([output, context], dim=1)\n",
        "            prediction = self.character_prob(output_context)\n",
        "            predictions.append(prediction.unsqueeze(1))\n",
        "\n",
        "        if mode == 'train':\n",
        "            attention_map = torch.stack(attentionPlot, dim=1)\n",
        "            return torch.cat(predictions, dim=1), attention_map\n",
        "        else:\n",
        "            return torch.cat(predictions, dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBqNJCW6ptnr"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    '''\n",
        "    We train an end-to-end sequence to sequence model comprising of Encoder and Decoder.\n",
        "    This is simply a wrapper \"model\" for your encoder and decoder.\n",
        "    '''\n",
        "    def __init__(self, input_dim, vocab_size, encoder_hidden_dim, decoder_hidden_dim, embed_dim, key_value_size=128):\n",
        "        super(Seq2Seq,self).__init__()\n",
        "        self.encoder = Encoder(input_dim, encoder_hidden_dim, key_value_size=key_value_size)\n",
        "        self.decoder = Decoder(vocab_size, decoder_hidden_dim, embed_dim, key_value_size=key_value_size)\n",
        "\n",
        "    def forward(self, x, x_len, y=None, mode='train',teacher_f = 0.1):\n",
        "        key, value, encoder_len = self.encoder(x, x_len)\n",
        "        if mode == 'train':\n",
        "            predictions,att = self.decoder(key, value, encoder_len, y=y, mode=mode,teacher_f = teacher_f )\n",
        "            return predictions,att\n",
        "        else:\n",
        "            predictions = self.decoder(key, value, encoder_len, y=y, mode=mode, teacher_f = teacher_f )\n",
        "            return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2yqEgU9qTvs"
      },
      "source": [
        "#reference: # https://github.com/salesforce/awd-lstm-lm/blob/dfd3cb0235d2caf2847a4d53e1cbd495b781b5d2/locked_dropout.py#L5\n",
        "class LockedDropout(nn.Module):\n",
        "    def __init__(self, dropout = 0.3):\n",
        "        super().__init__()\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def forward(self, x):\n",
        "        if not self.training or not self.dropout:\n",
        "            return x\n",
        "        m = x.data.new(1, x.size(1), x.size(2)).bernoulli_(1 - self.dropout)\n",
        "        mask = Variable(m, requires_grad=False) / (1 - self.dropout)\n",
        "        mask = mask.expand_as(x)\n",
        "        return mask * x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yt5S04qoqUIk"
      },
      "source": [
        "def idx2string(index_list,stop_index):\n",
        "    string_list = []\n",
        "\n",
        "    for curr_time in index_list:\n",
        "\n",
        "        curr_string = \"\"\n",
        "        for idx in curr_time:\n",
        "            if idx == stop_index:\n",
        "                break\n",
        "            else:\n",
        "                curr_string += index2letter[idx]\n",
        "\n",
        "        string_list.append(curr_string)\n",
        "\n",
        "    return string_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4B0kXK7pxDm",
        "outputId": "5f606610-169a-4df5-fad3-159961f09188"
      },
      "source": [
        "model = Seq2Seq(input_dim=40,vocab_size=len(LETTER_LIST), encoder_hidden_dim= 256,decoder_hidden_dim= 512,\n",
        "                embed_dim = 256, key_value_size=128)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (lstm): LSTM(40, 256, batch_first=True, bidirectional=True)\n",
              "    (plstm): Sequential(\n",
              "      (0): pBLSTM(\n",
              "        (blstm): LSTM(1024, 256, batch_first=True, bidirectional=True)\n",
              "      )\n",
              "      (1): pBLSTM(\n",
              "        (blstm): LSTM(1024, 256, batch_first=True, bidirectional=True)\n",
              "      )\n",
              "      (2): pBLSTM(\n",
              "        (blstm): LSTM(1024, 256, batch_first=True, bidirectional=True)\n",
              "      )\n",
              "    )\n",
              "    (key_network): Linear(in_features=512, out_features=128, bias=True)\n",
              "    (value_network): Linear(in_features=512, out_features=128, bias=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(34, 256, padding_idx=33)\n",
              "    (lstm1): LSTMCell(384, 512)\n",
              "    (lstm2): LSTMCell(512, 128)\n",
              "    (drop1): LockedDropout()\n",
              "    (drop2): LockedDropout()\n",
              "    (attention): Attention()\n",
              "    (character_prob): Linear(in_features=256, out_features=34, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BDUV3rhr7VH",
        "outputId": "39885086-78b3-4eb0-f2dc-3cbf2b1434eb"
      },
      "source": [
        "checkpoint = torch.load('/content/gdrive/My Drive/11785-hw/hw4/model3/tfAdd3_12.pickle')\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82,
          "referenced_widgets": [
            "65d5a8ba475940acb19f83bcc8cd5539",
            "004aa00e57dd46bc950e7cb998d6f08a",
            "39482056bcc3419398fc17cd0bc4c1f4",
            "b021d5f330f6406b8036072eeb21232e",
            "b52114c8387146878a9e4038ad7e1a63",
            "d880f4ff7a4c446ca883b6c803652c11",
            "e4b7e886618f4c5287bf276085fc04de",
            "76012fedd5ca49558311460acf1399ac"
          ]
        },
        "id": "cqJM_sSBqlq0",
        "outputId": "f9c387e2-4145-4a1f-d9c4-9faa9f192cab"
      },
      "source": [
        "predictions = np.array([])\n",
        "\n",
        "start_time = time.time()\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for idx, (x, x_lens) in tq(enumerate(test_loader)):\n",
        "\n",
        "        # 1) Set the inputs to the device.\n",
        "        x= x.to(device)\n",
        "        # 2) Pass your inputs, and length of speech into the model.\n",
        "        prediction = model(x,x_lens,mode = 'val')\n",
        "        idx_pred = prediction.argmax(-1).detach().cpu().numpy()\n",
        "        string_pred = idx2string(idx_pred, letter2index['<eos>'])\n",
        "        # print(string_pred.shape)\n",
        "        predictions = np.concatenate((predictions,string_pred))\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(\"predict time: \",end_time - start_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65d5a8ba475940acb19f83bcc8cd5539",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "predict time:  31.224238634109497\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZYo-ilDt90V",
        "outputId": "620f1cbb-38bc-46e6-e6c4-bbad24e5c001"
      },
      "source": [
        "len(predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2620"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJnBLyhurNn3"
      },
      "source": [
        "with open(\"/content/gdrive/My Drive/11785-hw/hw4/first_try.csv\",'w') as fh:\n",
        "    fh.write(\"id,label\\n\") #don't type wrong or kaggle can't identify it\n",
        "    for i in range(len(predictions)):\n",
        "        fh.write(\"{:},{:}\\n\".format(i,predictions[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "pDvzqpGit81k",
        "outputId": "b0a52305-c746-4eb9-ff4b-6a80a8f722e4"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/gdrive/My Drive/11785-hw/hw4/first_try.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>yes tirday were trembling for he health for th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>we were more interested at a centinical condit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>they said sir but i must have money to do that...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>aut of the gards my robbing the company i'll s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>but they could not in approve in a gace agains...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id                                              label\n",
              "0   0  yes tirday were trembling for he health for th...\n",
              "1   1  we were more interested at a centinical condit...\n",
              "2   2  they said sir but i must have money to do that...\n",
              "3   3  aut of the gards my robbing the company i'll s...\n",
              "4   4  but they could not in approve in a gace agains..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq3xlsDWutVZ",
        "outputId": "ed0051da-28d0-48d6-9383-5764f7a7b263"
      },
      "source": [
        "%cd /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkFV2TnhukFa",
        "outputId": "11911bcc-c8fc-49a9-b610-29ecebb978da"
      },
      "source": [
        "%cd ./gdrive/My Drive/11785-hw/hw4/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/11785-hw/hw4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0ouDoR7uu02",
        "outputId": "b32b7972-608d-4717-d479-60aeb19f4293"
      },
      "source": [
        "!kaggle competitions submit -c 11785-homework-4-part-2-las-slack -f first_try.csv -m \"gogogo\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "100% 291k/291k [00:05<00:00, 50.3kB/s]\n",
            "Successfully submitted to 11785 Homework 4 Part 2 : LAS - Slack"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}